{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento con retropropagación\n",
    "\n",
    "En este ejercicio implementaremos el algoritmo de retropropagación dentro del descenso por gradiente para actualizar todos los pesos de la red durante varias épocas. Para entrenar la red usaremos el conjunto de datos de calificaciones que vimos previamente.\n",
    "\n",
    "### Alumno: Trejo Arriaga Rodrigo Gerardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos paquetes y datos\n",
    "import numpy as np\n",
    "from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "# Definiciones útiles\n",
    "np.random.seed(21)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparámetros\n",
    "n_hidden = 2  # number of hidden units\n",
    "epochs = 900\n",
    "learnrate = 0.005\n",
    "\n",
    "# Obtenemos el número de entradas (features) asi como el número de ejemplos (n_records)\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# Creamos las matrices de los pesos.\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                        size=(n_features, n_hidden))\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                         size=n_hidden)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento - Parámetros originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2763000206585236\n",
      "Train loss:  0.27487280940102565\n",
      "Train loss:  0.27348146900538234\n",
      "Train loss:  0.2721253511981268\n",
      "Train loss:  0.2708037972995826\n",
      "Train loss:  0.2695161402601932\n",
      "Train loss:  0.2682617065761968\n",
      "Train loss:  0.26703981808591787\n",
      "Train loss:  0.26584979364857986\n",
      "Train loss:  0.26469095070807314\n",
      "Prediction accuracy: 0.425\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        ## Forward pass ##\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        output = sigmoid(np.dot(hidden_output, weights_hidden_output))\n",
    "\n",
    "        ## Backward pass ##\n",
    "        # Calcula el error de salida (target - actual)\n",
    "        error = y - output\n",
    "\n",
    "        # Calcula el término de error para la capa de salida\n",
    "        output_error_term = error * output * (1 - output)\n",
    "\n",
    "        # Propaga los errores a la capa oculta\n",
    "        hidden_error_term = np.dot(weights_hidden_output, output_error_term) * hidden_output * (1 - hidden_output)\n",
    "\n",
    "        # Actualiza el cambio en los pesos de la capa oculta a la capa de salida\n",
    "        del_w_hidden_output += output_error_term * hidden_output\n",
    "\n",
    "        # Actualiza el cambio en los pesos de la entrada a la capa oculta\n",
    "        del_w_input_hidden += hidden_error_term * x[:, None]\n",
    "\n",
    "    # Actualiza los pesos\n",
    "    weights_input_hidden += learnrate * del_w_input_hidden / n_records\n",
    "    weights_hidden_output += learnrate * del_w_hidden_output / n_records\n",
    "\n",
    "    # Imprime el error cuadrático medio en el conjunto de entrenamiento\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output, weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "# Calcula la precisión en los datos de prueba\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento - Parámetros modificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2698065764332278\n",
      "Train loss:  0.26033829974716854\n",
      "Train loss:  0.2524088524372422\n",
      "Train loss:  0.2458411869677293\n",
      "Train loss:  0.24044974472707353\n",
      "Train loss:  0.236055574656742\n",
      "Train loss:  0.23249521089471464\n",
      "Train loss:  0.22962479256103419\n",
      "Train loss:  0.22732098510705367\n",
      "Train loss:  0.22547999549054817\n",
      "Prediction accuracy: 0.750\n"
     ]
    }
   ],
   "source": [
    "# Hyperparámetros\n",
    "n_hidden = 6  # number of hidden units\n",
    "epochs = 900\n",
    "learnrate = 0.009\n",
    "\n",
    "# Obtenemos el número de entradas (features) asi como el número de ejemplos (n_records)\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# Creamos las matrices de los pesos.\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                        size=(n_features, n_hidden))\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                         size=n_hidden)\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        ## Forward pass ##\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        output = sigmoid(np.dot(hidden_output, weights_hidden_output))\n",
    "\n",
    "        ## Backward pass ##\n",
    "        # Calcula el error de salida (target - actual)\n",
    "        error = y - output\n",
    "\n",
    "        # Calcula el término de error para la capa de salida\n",
    "        output_error_term = error * output * (1 - output)\n",
    "\n",
    "        # Propaga los errores a la capa oculta\n",
    "        hidden_error_term = np.dot(weights_hidden_output, output_error_term) * hidden_output * (1 - hidden_output)\n",
    "\n",
    "        # Actualiza el cambio en los pesos de la capa oculta a la capa de salida\n",
    "        del_w_hidden_output += output_error_term * hidden_output\n",
    "\n",
    "        # Actualiza el cambio en los pesos de la entrada a la capa oculta\n",
    "        del_w_input_hidden += hidden_error_term * x[:, None]\n",
    "\n",
    "    # Actualiza los pesos\n",
    "    weights_input_hidden += learnrate * del_w_input_hidden / n_records\n",
    "    weights_hidden_output += learnrate * del_w_hidden_output / n_records\n",
    "\n",
    "    # Imprime el error cuadrático medio en el conjunto de entrenamiento\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output, weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "# Calcula la precisión en los datos de prueba\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "A través de la ejecución de este ejercicio de retropropagación, he consolidado mi entendimiento del entrenamiento de redes neuronales. Pude observar cómo la red ajusta iterativamente sus pesos en respuesta a los errores de predicción, mediante un proceso que refleja una forma fundamental de aprendizaje profundo. Este algoritmo no solo es el núcleo de muchas aplicaciones modernas de IA, sino que también actúa como una piedra angular conceptual para los profesionales del campo. Al implementar manualmente la retropropagación, reafirmamos la importancia de una comprensión profunda de los principios básicos que sustentan tecnologías más avanzadas y automatizadas, permitiéndonos apreciar las abstracciones de alto nivel que estas herramientas proporcionan. Con cada peso actualizado, damos un paso más hacia la creación de modelos predictivos precisos y robustos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbad788490f55b163920bee5e9d5e0cba00db5905dc94f4bdbe0011e55bf465f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
