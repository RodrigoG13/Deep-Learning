{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retropropagación a un paso\n",
    "\n",
    "La retropropagación nos brinda un mecanismo para entrenar redes de más de una capa. Su funcionamiento traslada el error en la predicción hacia atŕas usando la derivada parcial de dicho error con respecto de cada uno de los pesos. Es decir,\n",
    "\n",
    "$$\n",
    "\t\t\\frac{\\partial E}{\\partial w_{ho}} = \\frac{\\partial E}{\\partial h_o} \\frac{\\partial h_o}{\\partial w_{ho}}  =   \\frac{\\partial E}{\\partial h_o} y_h\n",
    "$$\n",
    "\n",
    "En este primer programa implementaremos el algoritmo de retropropagación para determinar los incrementos que debe tener cada capa de la red. En un siguiente ejercicio realizaremos todo el proceso de retropropagación.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/irvingvasquez/cv2course_intro_nn/blob/master/06_retropropagacion_base.ipynb)\n",
    "\n",
    "### Alumno: Trejo Arriaga Rodrigo Gerardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos paquetes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos funciones útiles\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos una arquitectura de red 3x2x1\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pase frontal\n",
    "\n",
    "Definimos el comportamiento de la red en el pase frontal.\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(WX)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "output = sigmoid(output_layer_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pase hacia atrás\n",
    "\n",
    "Calcula el cambio que deben de tener los pesos de acuerdo al error. Recordemos que para la capa de salida el término de error que se aplica es:\n",
    "\n",
    "$$\n",
    "\\delta_o = (y-\\hat{y})f'(h)\n",
    "$$\n",
    "\n",
    "Y para la capa oculta: \n",
    "\n",
    "$$\n",
    "\\delta_h = \\delta_o w_{h,o} f'(h_h)\n",
    "$$\n",
    "\n",
    "este último término de error es diferente para cada neurona con índice $h$ de la capa oculta. Es decir tendremos tantas h como neuronas tenga la capa oculta. Nota que aunque el ejercicio se puede resolver usando vectores e índices, lo implementaremos usando notación matricial.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backwards pass\n",
    "error = target - output\n",
    "del_err_output = error * sigmoid_prime(output_layer_in)\n",
    "del_err_hidden = del_err_output * np.multiply(weights_hidden_output, sigmoid_prime(hidden_layer_input))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que sabemos los términos de error que aplican en cada capa, procedemos a determinar los incrementos en cada capa.\n",
    "\n",
    "$$\n",
    "\\Delta w_{h,o} = \\Delta w_{h,o} + \\delta_o \\hat{y}_h \n",
    "$$\n",
    "\n",
    "$$\\Delta w_{i,h} = \\Delta w_{i,h} + \\delta_h x_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremento de los pesos oculta a salida:\n",
      "[0.00804047 0.00555918]\n",
      "Incremento de los pesos de entrada a oculta:\n",
      "[[ 1.77005547e-04 -5.11178506e-04]\n",
      " [ 3.54011093e-05 -1.02235701e-04]\n",
      " [-7.08022187e-05  2.04471402e-04]]\n"
     ]
    }
   ],
   "source": [
    "delta_w_h_o = learnrate * del_err_output * hidden_layer_output\n",
    "delta_w_i_h = learnrate * np.outer(x, del_err_hidden)\n",
    "\n",
    "\n",
    "print('Incremento de los pesos oculta a salida:')\n",
    "print(delta_w_h_o)\n",
    "\n",
    "print('Incremento de los pesos de entrada a oculta:')\n",
    "print(delta_w_i_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "La implementación de la retropropagación en esta práctica proporciona una comprensión detallada de los fundamentos del aprendizaje en redes neuronales. Este ejercicio manual de ajuste de pesos mediante el gradiente del error ofrece una ventana hacia la mecánica del aprendizaje automático y subraya la importancia de una correcta elección de la tasa de aprendizaje. Al dominar estos principios básicos, se establecen las bases para la exploración avanzada en inteligencia artificial, preparando el terreno para la utilización de herramientas automatizadas que manejan estas operaciones a gran escala."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbad788490f55b163920bee5e9d5e0cba00db5905dc94f4bdbe0011e55bf465f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
